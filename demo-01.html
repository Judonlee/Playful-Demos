<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<title>Perceptive Media: Playful Demos</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
</head>
<body>

	<canvas id="spectrum" width="1275" height="255" style="display: block; border: 1px solid #000;"></canvas>
	<canvas id="energy" width="1275" height="255" style="display: block; border: 1px solid #000;"></canvas>

	<p><button id="log">log</button></p>

<script type="text/javascript" src="assets/js/detectors/vad.js"></script>
<script type="text/javascript" src="assets/js/outputs/graph.js"></script>
<script type="text/javascript">

	var context = new (window.AudioContext || window.webkitAudioContext)();
	var microphone;
	var analyser;
	var javascriptNode;

	// Use Graph module to display the spectrum
	var graph_spectrum = new Graph({
		canvas: {
			id: 'spectrum',
			width: 1275,
			height: 255
		}
	});

	// Use Graph module to display the energy
	var graph_energy = new Graph({
		canvas: {
			id: 'energy',
			width: 1275,
			height: 255
		}
	});

	var myVad;

	function gotAudio(stream) {

		microphone = context.createMediaStreamSource(stream);

		// setup a javascript node
		// javascriptNode = context.createScriptProcessor(2048, 1, 1);
		javascriptNode = context.createScriptProcessor(512, 1, 1);
		// connect to destination, else it isn't called
		javascriptNode.connect(context.destination);

		// setup an analyzer
		analyser = context.createAnalyser();
		analyser.smoothingTimeConstant = 0.99; // 0.3;
		analyser.fftSize = 512;

		// analyser.maxDecibels = -20;
		// analyser.minDecibels = -60;

		// connect up the nodes
		microphone.connect(analyser);
		analyser.connect(javascriptNode);

		myVad = new vad(analyser);

		// when the javascript node is called
		// we use information from the analyzer node
		// to draw the volume
		javascriptNode.onaudioprocess = function() {

			// get the average for the first channel
			var array = new Uint8Array(analyser.frequencyBinCount);
			analyser.getByteFrequencyData(array);
			graph_spectrum.draw(array);

			graph_energy.draw([
				myVad.getEnergy(),
				myVad.getEnergyB(),
				myVad.getEnergyC(),
				255e8 * myVad.getEnergyD(),
				255e8 * myVad.energyMonitor(),
				255*myVad.getFrequency()/12000, // Normalized the frequency so 12kHz is max on graph
				-25.5*myVad.getSFM(),
				255*myVad.iterate()
			]);
		};

		// TMP - Remove to avoid feedback!
		// microphone.connect(context.destination);
	}

	function logError(error) {
		console.log(error.name + ": " + error.message);
	}

	// console.dir(navigator);
	// navigator.getUserMedia('audio', gotAudio, logError);

	if(navigator.getUserMedia) { // W3C
		navigator.getUserMedia({audio:true}, gotAudio, logError);
	} else if(navigator.webkitGetUserMedia) { // WebKit
		navigator.webkitGetUserMedia({audio:true}, gotAudio, logError);
	} else if(navigator.mozGetUserMedia) { // Mozilla
		navigator.mozGetUserMedia({audio:true}, gotAudio, logError);
	}

	console.log("sample rate: " + context.sampleRate);

	var logBtn = document.querySelector('#log');
	if(logBtn) {
		logBtn.addEventListener('click', function() {
			myVad.triggerLog();
		}, false);
	}

</script>
</body>
</html>
